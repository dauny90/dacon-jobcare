{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e729581-127c-4e74-a8f0-b0a1bbca221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c2194f-2446-4877-9d68-72c6e3912b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from pytorch_tabnet.tab_model  import TabNetClassifier\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1_Score(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        score = f1_score(y_true, (y_score[:, 1]>0.4)*1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846fcd1a-df6b-4efe-887e-b4fbc9e650aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_code(df_, d_code, h_code, l_code):\n",
    "    df_ = df_.copy()   \n",
    "\n",
    "    # D Code\n",
    "    df_['person_prefer_d_1_n'] = df_['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df_['person_prefer_d_1_s'] = df_['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df_['person_prefer_d_1_m'] = df_['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df_['person_prefer_d_1_l'] = df_['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df_['person_prefer_d_2_n'] = df_['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df_['person_prefer_d_2_s'] = df_['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df_['person_prefer_d_2_m'] = df_['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df_['person_prefer_d_2_l'] = df_['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df_['person_prefer_d_3_n'] = df_['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df_['person_prefer_d_3_s'] = df_['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df_['person_prefer_d_3_m'] = df_['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df_['person_prefer_d_3_l'] = df_['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    df_['contents_attribute_d_n'] = df_['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
    "    df_['contents_attribute_d_s'] = df_['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
    "    df_['contents_attribute_d_m'] = df_['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
    "    df_['contents_attribute_d_l'] = df_['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
    "\n",
    "    # H Code\n",
    "    #df_['person_prefer_h_1_u'] = df_['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    #df_['person_prefer_h_2_u'] = df_['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    #df_['person_prefer_h_3_u'] = df_['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    #df_['contents_attribute_h_u'] = df_['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 상위코드'])\n",
    "    \n",
    "    df_['contents_attribute_h_m'] = df_['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    df_['contents_attribute_h_l'] = df_['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    \n",
    "    df_['person_prefer_h_1_m'] = df_['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    df_['person_prefer_h_1_l'] = df_['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "\n",
    "    df_['person_prefer_h_2_m'] = df_['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    df_['person_prefer_h_2_l'] = df_['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "\n",
    "    df_['person_prefer_h_3_m'] = df_['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
    "    df_['person_prefer_h_3_l'] = df_['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
    "    \n",
    "    # L Code\n",
    "    df_['contents_attribute_l_n'] = df_['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
    "    df_['contents_attribute_l_s'] = df_['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
    "    df_['contents_attribute_l_m'] = df_['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
    "    df_['contents_attribute_l_l'] = df_['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed401fc-0b91-482f-b909-7b3dd4f1a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code = pd.read_csv('../data/dcode.csv', index_col=0).T.to_dict()\n",
    "h_code = pd.read_csv('../data/hcode.csv', index_col=0).T.to_dict()\n",
    "l_code = pd.read_csv('../data/lcode.csv', index_col=0).T.to_dict()\n",
    "\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_df = add_code(df_train, d_code, h_code, l_code)\n",
    "test_df = add_code(df_test, d_code, h_code, l_code)\n",
    "\n",
    "#test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770dced2-75b5-4164-9772-6d67123d65de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "train_df['aux'] = 'train'\n",
    "test_df['aux'] = 'test'\n",
    "test_df['target'] = -1\n",
    "\n",
    "columns = sorted(test_df.columns)\n",
    "train_df = train_df[columns]\n",
    "test_df = test_df[columns]\n",
    "\n",
    "train_df_aux = train_df.append(test_df)\n",
    "\n",
    "train_df_aux['count_person'] = train_df_aux.groupby('person_rn')['person_rn'].transform('count')\n",
    "train_df_aux['count_content'] = train_df_aux.groupby('contents_rn')['contents_rn'].transform('count')\n",
    "train_df_aux['count_person_content'] = train_df_aux.groupby('person_rn')['contents_rn'].transform('count')\n",
    "train_df_aux['count_content_person'] = train_df_aux.groupby('contents_rn')['person_rn'].transform('count')\n",
    "\n",
    "train_ = train_df_aux[train_df_aux['aux'] == 'train']\n",
    "test_ = train_df_aux[train_df_aux['aux'] == 'test']\n",
    "\n",
    "train_.drop(['aux'],axis=1,inplace=True)\n",
    "test_.drop(['aux','target'],axis=1,inplace=True)\n",
    "\n",
    "train = train_.copy()\n",
    "test = test_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5d8b6c-2f07-450b-80ef-1d9f31a5c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('../data/train.csv')\n",
    "#test_df = pd.read_csv('../data/test.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "#test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9bb797-2fed-47de-9c97-9d4ccebf12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train_df[train_df['contents_open_dt'].apply(lambda x: pd.Timestamp(x).month)<11].copy()\n",
    "#val = train_df[train_df['contents_open_dt'].apply(lambda x: pd.Timestamp(x).month)==11].copy()\n",
    "#train = train_df\n",
    "\n",
    "for df in [train,test]:\n",
    "    df['contents_open_dt'] = pd.to_datetime(df['contents_open_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ffb108-5a4d-41e9-9102-e4bf770aa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['contents_open_dt'] = pd.to_datetime(df['contents_open_dt'])\n",
    "\n",
    "for df in [train,test]:\n",
    "    df.drop(['id','person_prefer_f','person_prefer_g','person_rn','contents_rn'],axis=1,inplace=True)\n",
    "    #df.drop(['id','person_prefer_f','person_prefer_g'],axis=1,inplace=True)\n",
    "\n",
    "cat_columns = [col for col in train.columns if 'match' not in col and col not in ['target','contents_open_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13063e96-df56-46e2-b5f4-6aa7dd136aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['dia'] = pd.DatetimeIndex(df['contents_open_dt']).day\n",
    "    df['hora'] = pd.DatetimeIndex(df['contents_open_dt']).hour\n",
    "    df['dayofweek'] = df['contents_open_dt'].dt.dayofweek\n",
    "\n",
    "#cat_columns = [col for col in train.columns if 'match' not in col and col not in ['target','contents_open_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c89edb9-6210-41c6-9a44-b650d74f679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aux = train\n",
    "train = train_aux[train_aux['contents_open_dt'].apply(lambda x: pd.Timestamp(x).month)<10].copy()\n",
    "val = train_aux[train_aux['contents_open_dt'].apply(lambda x: pd.Timestamp(x).month)>=10].copy()\n",
    "\n",
    "for df in [train,val,test]:\n",
    "    df.drop(['contents_open_dt'],axis=1,inplace=True)\n",
    "\n",
    "columns = sorted(test.columns)\n",
    "train = train[columns+['target']]*1\n",
    "val = val[columns+['target']]*1\n",
    "test = test[columns]*1\n",
    "\n",
    "train_aux = train_aux[columns+['target']]*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5542ee44-0911-41c5-93f6-3ca6ff5dab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411367, 64)\n",
      "(90584, 64)\n",
      "(501951, 64)\n",
      "(46404, 63)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(train_aux.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4510e7ae-f307-47d4-8390-a56b3b949da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idxs = []\n",
    "cat_dims = []\n",
    "for idx, col in enumerate(train.columns):\n",
    "    if col in cat_columns: \n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_aux[col].values)\n",
    "        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        \n",
    "        train[col] = train[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        val[col] = val[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        test[col] = test[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        \n",
    "        train_aux[col] = train_aux[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n",
    "        \n",
    "        cat_idxs.append(idx)\n",
    "        cat_dims.append(len(le_dict)+1)\n",
    "\n",
    "X_train = train.drop('target',axis=1).values\n",
    "y_train = train['target'].values\n",
    "X_val = val.drop('target',axis=1).values\n",
    "y_val = val['target'].values\n",
    "X_test = test.values\n",
    "eval_set = (X_val,y_val)\n",
    "\n",
    "X_train_full = train_aux.drop('target',axis=1).values\n",
    "y_train_full = train_aux['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8002b4d9-747a-429b-ba54-87cbfda77f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "clf = TabNetClassifier(seed = 1990,\n",
    "                       n_steps=6,\n",
    "                       cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=3,\n",
    "                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n",
    "                       mask_type='entmax', # \"sparsemax\",entmax\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d901127e-3832-4f4f-9916-bf6e27185384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.67536 | train_logloss: 0.65356 | train_f1: 0.68219 | val_logloss: 0.65755 | val_f1: 0.67381 |  0:01:38s\n",
      "epoch 1  | loss: 0.64451 | train_logloss: 0.63643 | train_f1: 0.69562 | val_logloss: 0.64299 | val_f1: 0.68329 |  0:03:17s\n",
      "epoch 2  | loss: 0.63499 | train_logloss: 0.62764 | train_f1: 0.69944 | val_logloss: 0.63811 | val_f1: 0.68418 |  0:04:56s\n",
      "epoch 3  | loss: 0.62999 | train_logloss: 0.62455 | train_f1: 0.7025  | val_logloss: 0.63786 | val_f1: 0.68569 |  0:06:35s\n",
      "epoch 4  | loss: 0.62615 | train_logloss: 0.62062 | train_f1: 0.70601 | val_logloss: 0.64089 | val_f1: 0.68773 |  0:08:13s\n",
      "epoch 5  | loss: 0.6229  | train_logloss: 0.61219 | train_f1: 0.704   | val_logloss: 0.63855 | val_f1: 0.67968 |  0:09:52s\n",
      "epoch 6  | loss: 0.62027 | train_logloss: 0.61509 | train_f1: 0.70913 | val_logloss: 0.63901 | val_f1: 0.6886  |  0:11:31s\n",
      "epoch 7  | loss: 0.61826 | train_logloss: 0.60502 | train_f1: 0.71026 | val_logloss: 0.64066 | val_f1: 0.68003 |  0:13:11s\n",
      "epoch 8  | loss: 0.61658 | train_logloss: 0.6042  | train_f1: 0.70428 | val_logloss: 0.64446 | val_f1: 0.66834 |  0:14:50s\n",
      "epoch 9  | loss: 0.61503 | train_logloss: 0.60351 | train_f1: 0.71146 | val_logloss: 0.63896 | val_f1: 0.67959 |  0:16:28s\n",
      "epoch 10 | loss: 0.61379 | train_logloss: 0.60735 | train_f1: 0.71331 | val_logloss: 0.63928 | val_f1: 0.68749 |  0:18:08s\n",
      "epoch 11 | loss: 0.61277 | train_logloss: 0.60583 | train_f1: 0.71343 | val_logloss: 0.64078 | val_f1: 0.67557 |  0:19:47s\n",
      "epoch 12 | loss: 0.61213 | train_logloss: 0.60159 | train_f1: 0.71292 | val_logloss: 0.64534 | val_f1: 0.6762  |  0:21:26s\n",
      "epoch 13 | loss: 0.61202 | train_logloss: 0.60087 | train_f1: 0.70788 | val_logloss: 0.64739 | val_f1: 0.66438 |  0:23:05s\n",
      "epoch 14 | loss: 0.61137 | train_logloss: 0.59907 | train_f1: 0.71546 | val_logloss: 0.63925 | val_f1: 0.67998 |  0:24:44s\n",
      "epoch 15 | loss: 0.61102 | train_logloss: 0.60262 | train_f1: 0.70926 | val_logloss: 0.64752 | val_f1: 0.66725 |  0:26:23s\n",
      "epoch 16 | loss: 0.61053 | train_logloss: 0.59701 | train_f1: 0.71749 | val_logloss: 0.64328 | val_f1: 0.68124 |  0:28:01s\n",
      "epoch 17 | loss: 0.61037 | train_logloss: 0.60314 | train_f1: 0.71786 | val_logloss: 0.6396  | val_f1: 0.68316 |  0:29:41s\n",
      "epoch 18 | loss: 0.60992 | train_logloss: 0.59762 | train_f1: 0.71359 | val_logloss: 0.645   | val_f1: 0.67066 |  0:31:26s\n",
      "epoch 19 | loss: 0.60965 | train_logloss: 0.59691 | train_f1: 0.71692 | val_logloss: 0.64966 | val_f1: 0.67746 |  0:33:10s\n",
      "epoch 20 | loss: 0.60972 | train_logloss: 0.60386 | train_f1: 0.71644 | val_logloss: 0.63982 | val_f1: 0.68644 |  0:34:55s\n",
      "epoch 21 | loss: 0.60927 | train_logloss: 0.59518 | train_f1: 0.7143  | val_logloss: 0.64691 | val_f1: 0.67091 |  0:36:38s\n",
      "epoch 22 | loss: 0.60937 | train_logloss: 0.59698 | train_f1: 0.71657 | val_logloss: 0.64739 | val_f1: 0.6755  |  0:38:16s\n",
      "epoch 23 | loss: 0.60904 | train_logloss: 0.59551 | train_f1: 0.71723 | val_logloss: 0.642   | val_f1: 0.67666 |  0:39:55s\n",
      "epoch 24 | loss: 0.60892 | train_logloss: 0.59888 | train_f1: 0.71895 | val_logloss: 0.64164 | val_f1: 0.68146 |  0:41:34s\n",
      "epoch 25 | loss: 0.60888 | train_logloss: 0.59239 | train_f1: 0.7187  | val_logloss: 0.64802 | val_f1: 0.67846 |  0:43:13s\n",
      "epoch 26 | loss: 0.60852 | train_logloss: 0.59413 | train_f1: 0.71909 | val_logloss: 0.64397 | val_f1: 0.68049 |  0:44:51s\n",
      "epoch 27 | loss: 0.60859 | train_logloss: 0.59451 | train_f1: 0.71883 | val_logloss: 0.64636 | val_f1: 0.68233 |  0:46:30s\n",
      "epoch 28 | loss: 0.60844 | train_logloss: 0.60266 | train_f1: 0.7177  | val_logloss: 0.64315 | val_f1: 0.68379 |  0:48:10s\n",
      "epoch 29 | loss: 0.6083  | train_logloss: 0.74055 | train_f1: 0.70852 | val_logloss: 0.80389 | val_f1: 0.67045 |  0:49:49s\n",
      "epoch 30 | loss: 0.60918 | train_logloss: 0.61097 | train_f1: 0.71934 | val_logloss: 0.64622 | val_f1: 0.68378 |  0:51:29s\n",
      "epoch 31 | loss: 0.60816 | train_logloss: 0.59656 | train_f1: 0.7188  | val_logloss: 0.64387 | val_f1: 0.6848  |  0:53:08s\n",
      "epoch 32 | loss: 0.60792 | train_logloss: 0.59103 | train_f1: 0.71889 | val_logloss: 0.64875 | val_f1: 0.67636 |  0:54:47s\n",
      "epoch 33 | loss: 0.60814 | train_logloss: 0.59819 | train_f1: 0.69868 | val_logloss: 0.65694 | val_f1: 0.64483 |  0:56:26s\n",
      "epoch 34 | loss: 0.60779 | train_logloss: 0.59649 | train_f1: 0.71796 | val_logloss: 0.64706 | val_f1: 0.68041 |  0:58:06s\n",
      "epoch 35 | loss: 0.60741 | train_logloss: 0.59555 | train_f1: 0.71905 | val_logloss: 0.64792 | val_f1: 0.6773  |  0:59:45s\n",
      "epoch 36 | loss: 0.60761 | train_logloss: 0.59472 | train_f1: 0.71884 | val_logloss: 0.64551 | val_f1: 0.678   |  1:01:24s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 6 and best_val_f1 = 0.6886\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_name=['train', 'val'],\n",
    "    eval_metric=['logloss','f1'],\n",
    "    max_epochs=200 , patience=30,\n",
    "    batch_size=256,\n",
    "    virtual_batch_size=256,\n",
    "    num_workers=1,\n",
    "    drop_last=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e80b428-6374-4e71-934f-822638f9a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68445d23-a47d-4418-8f46-fe5a017cc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6723496543518532\n",
      "0.6769467885428271\n",
      "0.6819084094252821\n",
      "0.6868764821737208\n",
      "0.6885998729082821\n",
      "0.6395352596919693\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_val, (preds[:, 1]>0.2)*1))\n",
    "print(f1_score(y_val, (preds[:, 1]>0.25)*1))\n",
    "print(f1_score(y_val, (preds[:, 1]>0.3)*1))\n",
    "print(f1_score(y_val, (preds[:, 1]>0.35)*1))\n",
    "print(f1_score(y_val, (preds[:, 1]>0.4)*1))\n",
    "print(f1_score(y_val, (preds[:, 1]>0.5)*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa7295-34f7-489c-adf7-b154cafd776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train_full, \n",
    "    y_train=y_train_full,\n",
    "    max_epochs=20,\n",
    "    batch_size=256,\n",
    "    patience=10,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=1,\n",
    "    drop_last=False,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3912a5b-9b35-4d26-838e-f3ca2173ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "preds = (preds[:,1]>0.4)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "245a31e3-0d13-4f23-a870-1ac5e5ce46e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file to submit\n",
    "sample['target'] = preds\n",
    "sample.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e0f04ce-b045-46e4-9b8a-8a2e4cdf0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensamble\n",
    "\n",
    "sub1 = pd.read_csv('sub_tabnet_26.csv')\n",
    "sub2 = pd.read_csv('sub_tabnet_23.csv')\n",
    "sub3 = pd.read_csv('sub_tabnet_25.csv')\n",
    "sub4 = pd.read_csv('sub_tabnet_28.csv')\n",
    "#sub5 = pd.read_csv('sub_tabnet_9.csv')\n",
    "\n",
    "sub1['target_final'] = round((sub1['target'] + sub2['target'] + sub3['target']+ sub4['target'])/4,0).astype(int)\n",
    "sub1.drop(['target'],axis = 1,inplace = True)\n",
    "\n",
    "sub1.drop(['target'],axis = 1,inplace = True)\n",
    "sub1.columns = ['id','target']\n",
    "sub1.to_csv('sub_tabnet_29.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
